
<!DOCTYPE html> 
<!--
	Noam's theme, based on Readnik scriptogr.am theme
-->
<html lang="en">
<head>
  <title>Noam Ross | FasteR! HigheR! StrongeR! - A Guide to Speeding Up R Code for Busy People</title>
  <meta name="description" content=" " />
  <meta name="author" content="Noam Ross">
  <meta name="viewport" content="width=device-width; initial-scale=1.0; maximum-scale=1.0;">
  <meta name="apple-mobile-web-app-capable" content="yes"/>
  <meta name="ROBOTS" content="INDEX,FOLLOW">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta charset="utf-8">
  <meta property="og:url" content="">
  <meta property="og:site_name" content="Noam Ross">
  <link rel="icon" type="image/x-icon" href="/assets/themes/noamblog/atom.ico">
  <link href="/assets/themes/noamblog/css/style.css" rel="stylesheet" type="text/css" media="all">
  <link href="http://feeds.feedburner.com/noamross" rel="alternate" type="application/rss+xml" title="Noam Ross" />
  <script type="text/javascript">

    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-30394461-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
 </script>
 <script type="text/javascript"> 
    function typeset() {
      MathJax.Hub.Queue(["Typeset",MathJax.Hub]);
    }
    function disqus_config() {
      this.callbacks.onNewComment = [typeset];
      this.callbacks.onInit = [typeset];
    }
  </script>
  <script src="http://cachedcommons.org/javascripts/text/prettify-min.js" type="text/javascript"></script>
  <script src="http://cachedcommons.org/javascripts/text/showdown-min.js" type="text/javascript"></script>
  <script src="http://cachedcommons.org/javascripts/jquery/jquery.disqus.js" type="text/javascript"></script>
  <script type="text/javascript" src="/assets/themes/noamblog/app.js"></script>  
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script>
  <script type="text/x-mathjax-config">  MathJax.Hub.Config({ "HTML-CSS": { availableFonts: ["TeX"], webfont: [null] }} ); </script>
  <script type="text/x-mathjax-config">  MathJax.Hub.Config({ TeX: { extensions: ["autobold.js"] }} ); </script>
  <script type="text/javascript">var switchTo5x=true;</script>
  <script type="text/javascript" src="http://w.sharethis.com/button/buttons.js"></script>
  <script type="text/javascript">stLight.options({publisher: "4376beef-ffcc-441e-a877-904acf7f379b", theme:'8', onhover:false, doNotHash:true, doNotCopy:true, hashAddressBar:false}); </script>
  <script type="text/javascript">
      function chgifr(url, iframe)  {
          document.getElementById(iframe).src = url;
      }
  </script>
  <script type="text/javascript">
      function showhide(id) {
           var e = document.getElementById(id);
           if(e.style.display == 'block')
              e.style.display = 'none';
           else
              e.style.display = 'block';
        }
  </script>
</head>
<body>
<div class="wrapper">
  <div class="blog">
 
      <div id="menu" class="menu-top">
        <div class="blog-info">
          <h1><a href="/index.html">Noam Ross</a></h1>
          <div class="blog-description">
           <h2>Real-time research in ecology, economics, and sustainability</h2>
          </div>
         </div>
          <div class="pages">
            
            <!-- Lockerz Share BEGIN -->
            <a class="a2a_dd" href="http://www.addtoany.com/share_save" tile"Share this Page"><span class="shareicon"><span class="hide">Share</span></span></a>
            <script type="text/javascript">
            var a2a_config = a2a_config || {};
            a2a_config.onclick = 0;
            a2a_config.show_title = 1;
            a2a_config.color_main = "FFFFFF";
            a2a_config.color_border = "FFFFFF";
            a2a_config.color_link_text = "45462f";
            a2a_config.color_link_text_hover = "575757";
            a2a_config.prioritize = ["twitter", "facebook", "tumblr", "email", "delicious", "linkedin", "stumbleupon", "google_plus"];
            </script>
            <script type="text/javascript" src="http://static.addtoany.com/menu/page.js"></script>
            <!-- Lockerz Share END -->
            
            <a href="http://feeds.feedburner.com/noamross" title="Subscribe via Feedburner RSS"> <span class="rssicon"> <span class="hide">RSS</span></span></a>
            
             
             
            


  
    
  
    
    	
    	<a href="/about.html">About</a>
    	
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
    	
    	<a href="/connect.html">Connect</a>
    	
    
  
    
  
    
    	
    	<a href="/index.html">Blog</a>
    	
    
  
    
  
    
  
    
    	
    	<a href="/publications.html">Publications</a>
    	
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
    	
    	<a href="/tags.html">Topics</a>
    	
    
  
    
  



            
        </div>
      </div>

      <div class="container">

        <div class="content">
          
<div id="headblock">
<h1 id="page.title"><a href="/blog/2013/4/25/faster-talk.html">FasteR! HigheR! StrongeR! - A Guide to Speeding Up R Code for Busy People</a></h1>
<p>by <em>Noam Ross</em>, 25 April 2013</p>
<hr />
</div>
<div class="contenttext"><p><p><em>This is an overview of tools for speeding up your R code that I wrote for the <a href="http://www.noamross.net/davis-r-users-group.html">Davis R Users’ Group</a>.</em></p>
<h2 id="first-ask-why">First, Ask “Why?”</h2>
<p>It’s customary to <a href="http://en.wikiquote.org/wiki/Donald_Knuth">quote Donald Knuth</a> at this point, but instead I’ll quote my twitter buddy Ted Hart to illustrate a point:</p>
<blockquote class="twitter-tweet"><p>
I’m just going to say it.I like for loops in <a href="https://twitter.com/search/%23Rstats">#Rstats</a>, makes my code readable.All you [a-z]*ply snobs can shove it!
</p>
— Ted Hart (@DistribEcology) <a href="https://twitter.com/DistribEcology/status/311581025870426113">March 12, 2013</a>
</blockquote>
<script async src="http://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Code optimization is a matter is a matter of personal taste and <em>priorities</em>. There may be some ways of writing code that are better or worse, and there are definitely ways that will make it run faster, but before you dive into optimization, you should ask yourself these questions:</p>
<h4 id="do-you-want-your-code-to-be-readable">(1) Do you want your code to be <em>readable</em>?</h4>
<p>If you need to explain your code to yourself or others, or you will need to return to it in a few months time and understand what you wrote, it’s important that you write it in a way that is easy to understand. Comments, indenting, and formatting go a long way, but your choices make a difference, as Ted notes above.</p>
<p>Some optimal code can be hard to read. For instance, and curly braces can be faster than parentheses. But which is more intuitive to read?<sup><a href="#fn1" class="footnoteRef" id="fnref1">1</a></sup></p>
<h4 id="do-you-want-your-code-to-be-sharable1">(2) Do you want your code to be <em>sharable</em>?<sup><a href="#fn2" class="footnoteRef" id="fnref2">2</a></sup></h4>
<p>Most of the considerations of (1) apply here, but they have to be balanced with the fact that, if your code is painfully slow, others are not going to want or have time to use it.</p>
<p>Also, some optimization strategies don’t transfer well. If you use parallel processing, it won’t be usable to others who don’t have multicore computers. Some tricks for speeding up code will work well as a quick-and-dirty fix, but are likely to break in new versions of R or are disallowed from CRAN packages altogether.</p>
<h4 id="do-you-have-other-shit-to-do">(3) Do you have other shit to do?</h4>
<p>No? Please contact me and I’ll help you with that. Yes? You are among the 90% or R users who’s first priority is not computer programming. The time spent optimizing code is often longer than the computing time actually saved. Use the simple solutions and you can get on with your research/life.</p>
<p>With these in mind, I’ll go through some strategies for speeding up your R computations. Because I’m especially mindful of consideration #3, this guide is somewhat in the reverse of traditional tutorials on this topic. I’m going to talk about the blunt instruments first, then get into the idiosyncrasies of code.</p>
<h2 id="get-a-bigger-computer">Get a Bigger Computer</h2>
<p>If you have a task that only needs to be accomplished a few times, you might be best off finding more resources rather than re-writing your code. You have an Amazon.com account, right? Amazon rents virtual machines on the web. It’s so easy to set one up that I accidentally started one today without meaning to while searching for the link. The cost of computing power roughly equivalent to my 2011 MacBook Pro is <em>13¢ per hour</em>. You can have 100 MacBooks of computing power for <a href="http://greentheo.scroggles.com/2009/11/13/amazon-ec2-providing-100-macbooks-of-power-for-minimum-wage/">less than minimum wage</a>.<sup><a href="#fn3" class="footnoteRef" id="fnref3">3</a></sup> These virtual machines can also have much more memory than your laptop or desktop.</p>
<p>Sometimes you don’t even need more computing power, you just need to run R on some other computer without tying up your machine for hours. In any case, consider this option. If you just need to run a task once, and you think you are going to have to spend more than an hour rewriting your code, you might as well use that hour getting a virtual machine set up and never worry about computing power again.</p>
<p>Cloud resources like Amazon aren’t the only way to get more computer power. If you’re at a university, there are probably high-power computing clusters available to you. Depending on your particular set-up, you may need to to run your program in <a href="http://stat.ethz.ch/R-manual/R-patched/library/utils/html/BATCH.html">batch mode</a> to use such clusters. Personally, I think that a cloud-based service like Amazon avoids administrative hassle if you are on a short deadline or have a one-off task, but if you need lots of power regularly, getting in on a local cluster is worthwhile.</p>
<p>The most user-friendly way to use cloud computing is to set up a server to run RStudio, which can then be accessed by a web browser and works just like it would on your desktop. Bioconductor has a <a href="http://bioconductor.org/help/bioconductor-cloud-ami/">step by step guide</a> to starting an Amazon Web Instance that they’ve pre-configured this way. There are a couple of other useful guides to doing the same thing by <a href="http://www.louisaslett.com/RStudio_AMI/">Louis Aslett (including a video)</a> and <a href="http://inundata.org/2011/03/30/r-ec2-rstudio-server/">Karthik Ram</a>. Read all of these and you should be able to set yourself up in an hour or two.</p>
<p>A fancier alternative is the experimental <a href="https://code.google.com/p/segue/">Segue package</a>, which provides an <code>apply()</code> function variant, <code>emrapply()</code>, that sends commands from your local R session to Amazon servers and returns the results. An introductory guide is <a href="http://jeffreybreen.wordpress.com/2011/01/10/segue-r-to-amazon-elastic-mapreduce-hadoop/">here</a>.</p>
<p>Of course, if you are writing software that you expect others to run on normal laptop and desktop computers, you’ll want to make sure it does so at a reasonable speed. In this case, running your software in the cloud may not make sense.</p>
<h2 id="parallel-processing">Parallel Processing</h2>
<p>Parallel processing used to be a very fancy thing, but with recent R packages, it can be implemented with very little programming time. Parallel processing breaks up your task, splits it among multiple processors, and puts the components back together. This is very useful and easy if you have a task that <em>can</em> be split up, especially without the different parts needing to “talk to” each other.</p>
<p>On your typical laptop or desktop, implementing parallel processing in your R code might speed up your program by a factor of 2 to 4. However, if you have a big machine, or you followed my advice in the last section, you can take advantage of large computers with many CPUs or “cores”.</p>
<p>I’m not going to get into the nitty gritty of setting up parallel processes and the various packages that do so e.g. <code>multicore</code>, <code>snow</code>,<code>snowfall</code>, <code>doParallel</code>,<code>foreach</code>, <code>plyr</code>,…) because <a href="http://www.linkedin.com/pub/jacob-teter/9/7b2/684">Jacob Teter</a> will give a presentation on that at <a href="http://www.noamross.net/davis-r-users-group.html">D-RUG</a> next week. Instead I’ll discuss a bit about <em>when</em> this approach might be appropriate.</p>
<p>Essentially, parallel processing works best when you have a task that has to be completed many times, but each repeat is independent. For instance, if you are repreating a simulation, and in each case are drawing new parameters from a distribution, that is an easily parallelizable task. However, if you are simulating population dynamics, in which each time step you need the outputs of the previous time steps, than you can’t split up each time step into parallel components.</p>
<p>A good rule of thumb is that if you can wrap your task in an <code>apply</code> function or one of its variants, it’s a good option for parallelization. In fact most implementations of parallel processing in R are versions of <code>apply</code>.</p>
<p>Not every task runs better in parallel. When you run a task in parallel, your computer “dispatches” each task to a CPU core. This dispatching adds computational overhead. So, it’s usually best to try to minimize the number of dispatches. In most cases you are going to have a small number of computing cores relative to your tasks. A powerful laptop or desktop will have 2, 4, or 8 cores, and even the most powerful Amazon virtual machine has 88.</p>
<p>The following would be a poor use of parallel computing:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">aaply</span>(<span class="dv">1</span>:<span class="dv">10000</span>, <span class="dv">1</span>, function(x) <span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dt">mean=</span>x), <span class="dt">.parallel=</span><span class="ot">TRUE</span>)</code></pre>
<p>This would dispatch the very small task of generating a random number 10,000 times. The dispatching would probably take more time than the actual calculations. Instead, organize the tasks into blocks, and dispatch each block of tasks, for instance:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">aaply</span>(<span class="kw">seq</span>(<span class="dv">1</span>,<span class="dv">10000</span>,<span class="dv">100</span>), function(x) <span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dt">mean=</span>x+(<span class="dv">1</span>:<span class="dv">100</span>), <span class="dt">.parallel=</span><span class="ot">TRUE</span>)</code></pre>
<p>This sends the task of generating 100 numbers to each core, reducing the overhead.</p>
<p><strong><em>[Update 4/26/2013: As <a href="https://twitter.com/vsbuffalo/status/327564597282369536">Vince Buffalo points out</a>, random number generation requires that R keep track of state, so may not be a good example of a parallel-izable task]</em></strong></p>
<p>In practice, this means that you want to “parallelize” your code at the highest, or chunkiest level. If you have a series of nested loops, for instance, you will want to run the highest-level loop in parallel.</p>
<p>Note that <a href="http://lookingatdata.blogspot.se/2013/01/speeding-up-r-computations-pt-iii.html">more cores is not always better</a>. For reasons I don’t completely understand, the overhead of using more cores is not always worth it, so it may be better to use, say 16, rather than 64 codes. Some experimentation will help here.</p>
<p>One other thing: if you can limit the parallel processes to computational tasks, and avoid things like reading/writing to disk or downloading files in the parallel code, you’ll be less likely to run into problems.</p>
<p>A disadvantage of parallel computing is that it is not available to everyone. People run code on different machines. If you are writing software that you expect to share with others (and as a scientist, you should ALWAYS be prepared to share your work on request, and post your code as a supplement to your paper), you will want to provide an option to run it not in parallel. I like to do something like this:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#This script uses parallel processing if p.flag=TRUE.  Set up a parallel </span>
<span class="co">#cluster as appropriate for your machine as appropriate. (the commented code </span>
<span class="co">#below will use 2 cores on a multicore computer)</span>
<span class="co">#library(doParallel)</span>
<span class="co">#cl &lt;- makeCluster(2)  # Use 2 cores</span>
<span class="co">#registerDoParallel(cl) # register these 2 cores with the &quot;foreach&quot; package</span>
<span class="kw">library</span>(plyr)
p.flag=<span class="ot">FALSE</span>  <span class="co"># Change to TRUE if using parallel processing</span>
.
.
.
 <span class="kw">aaply</span>(<span class="kw">seq</span>(<span class="dv">1</span>,<span class="dv">10000</span>,<span class="dv">100</span>), function(x) <span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dt">mean=</span>x+(<span class="dv">1</span>:<span class="dv">100</span>), 
      <span class="dt">.parallel=</span>p.flag)</code></pre>
<h2 id="compiling-functions">Compiling Functions</h2>
<p>R code is interpreted when it is run, unlike some other languages, which are first compiled. This is one reason why functions written in C are often faster than functions written in R.</p>
<p>However, R has compiling ability, which can speed up functions <a href="http://dirk.eddelbuettel.com/blog/2011/04/12/#the_new_r_compiler_package">by a factor or 3 or 4 <em>in some cases</em></a>. Compiling functions just requires calling <code>cmpfun()</code> in the base <code>compiler</code> package. Here’s an example:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(compiler)
f &lt;-<span class="st"> </span>function(n, x) for (i in <span class="dv">1</span>:n) x =<span class="st"> </span>(<span class="dv">1</span> +<span class="st"> </span>x)^(-<span class="dv">1</span>)
g &lt;-<span class="st"> </span><span class="kw">cmpfun</span>(f)

<span class="kw">library</span>(microbenchmark)
compare &lt;-<span class="st"> </span><span class="kw">microbenchmark</span>(<span class="kw">f</span>(<span class="dv">1000</span>, <span class="dv">1</span>), <span class="kw">g</span>(<span class="dv">1000</span>, <span class="dv">1</span>), <span class="dt">times =</span> <span class="dv">1000</span>)

<span class="kw">library</span>(ggplot2)
<span class="kw">autoplot</span>(compare)</code></pre>
<div class="figure">
<img src="http://dl.dropbox.com/u/3356641/blogstuff/unnamed-chunk-1.png" />
</div>
<pre class="sourceCode r"><code class="sourceCode r">
compare</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">## Unit: microseconds
##        expr   min    lq median     uq  max neval
##  f(1000, 1) 950.0 991.3 1024.7 1087.2 2799  1000
##  g(1000, 1) 218.2 228.0  238.2  257.3 1743  1000</code></pre>
<p>(See the benchmarking section below for more on comparing functions with <code>microbenchmark()</code>)</p>
<p><code>cmpfun()</code> works well in cases like this - when you are defining a new function that is mostly numerical manipulation. It doesn’t help with functions that call a lot of other R functions, or involve manipulating and translating between data types. It also doesn’t work well on already-defined R functions, which have been pre-compiled since R 2.14 and are sometimes written in compiled languages like C. For instance, if I try to compile this <code>paste()</code>-based function, I get no improvement:</p>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span>function(n) <span class="kw">paste</span>(<span class="dv">1</span>:n, <span class="dt">collapse =</span> <span class="st">&quot; &quot;</span>)
g &lt;-<span class="st"> </span><span class="kw">cmpfun</span>(f)
compare &lt;-<span class="st"> </span><span class="kw">microbenchmark</span>(<span class="kw">f</span>(<span class="dv">1000</span>), <span class="kw">g</span>(<span class="dv">1000</span>), <span class="dt">times =</span> <span class="dv">1000</span>)
<span class="kw">autoplot</span>(compare)</code></pre>
<div class="figure">
<img src="http://dl.dropbox.com/u/3356641/blogstuff/unnamed-chunk-2.png" />
</div>
<pre class="sourceCode r"><code class="sourceCode r">compare</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">## Unit: microseconds
##     expr   min    lq median    uq  max neval
##  f(1000) 320.2 331.8  353.9 429.2 1889  1000
##  g(1000) 320.7 330.6  352.8 412.5 2530  1000</code></pre>
<p>You can also <a href="http://www.r-statistics.com/2012/04/speed-up-your-r-code-using-a-just-in-time-jit-compiler/">enable just-in-time compiling in R</a>, which will automatically compile EVERY function the first time that it is run. This will slow down R quite a bit at first, as each function must be compiled before it is run the first time, but but then speed it up later. Just add this to the start of your script</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(compiler)
<span class="kw">enableJIT</span>(<span class="dv">1</span>)</code></pre>
<p>The numeric argument in <code>enableJIT</code> specifies the “level” of compilation. At level 2 and 3 more functions are compiled. In a few rare cases enableJIT will <em>slow down</em> code, particularly, if most of it is already pre-compiled or written in C, and/or if the code <em>creates</em> functions repeatedly, which then need to be compiled every time. This is more likely to happen with <code>enableJIT(2)</code> or <code>enableJIT(3)</code>, though these have the potential to speed up code more, as well.</p>
<h2 id="diagnosis-profiling-and-benchmarking">Diagnosis: Profiling and Benchmarking</h2>
<p>OK, the tools I described above are all blunt instruments that could speed up many types of code. However, if they fail you or aren’t feasible, you’re going to need to know something about what is slowing your code down.</p>
<h3 id="benchmarking">Benchmarking</h3>
<p>Benchmarking is a way to test and compare the speed of functions.</p>
<p>Traditionally, <code>system.time(replicate())</code> could be used to time functions, but the <code>microbenchmark</code> package is a better option for benchmarking individuals calls and functions. If you have identified a function that is called many times in your code and needs to be speeded up, you can write or try out several different versions, using <code>microbenchmark</code> to compare them. Here’s the example from above:</p>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span>function(n, x) for (i in <span class="dv">1</span>:n) x =<span class="st"> </span>(<span class="dv">1</span> +<span class="st"> </span>x)^(-<span class="dv">1</span>)
g &lt;-<span class="st"> </span><span class="kw">cmpfun</span>(f)

<span class="kw">library</span>(microbenchmark)
compare &lt;-<span class="st"> </span><span class="kw">microbenchmark</span>(<span class="kw">f</span>(<span class="dv">1000</span>, <span class="dv">1</span>), <span class="kw">g</span>(<span class="dv">1000</span>, <span class="dv">1</span>), <span class="dt">times =</span> <span class="dv">1000</span>)

<span class="kw">library</span>(ggplot2)
<span class="kw">autoplot</span>(compare)</code></pre>
<div class="figure">
<img src="http://dl.dropbox.com/u/3356641/blogstuff/unnamed-chunk-3.png" />
</div>
<pre class="sourceCode r"><code class="sourceCode r">compare</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">## Unit: microseconds
##        expr   min     lq median     uq   max neval
##  f(1000, 1) 958.2 1064.2 1220.5 1795.7 11595  1000
##  g(1000, 1) 219.8  243.7  271.4  379.4  1370  1000</code></pre>
<p>All <code>microbenchmark</code> needs as inputs are a series of expressions to compare. <code>times</code> is an optional parameter of the number of times to test each function (default 100). Microbenchmark randomizes the test order and discards some “warmup” tests. The full distribution is returned as a data frame, but only the summaries are printed.</p>
<p>The <code>autoplot()</code> command draws a comparison of distribution times using <code>ggplot()</code></p>
<h3 id="profiling">Profiling</h3>
<p>Benchmarking is good for comparing small functions. <em>Profiling</em> examines your code to determine what parts of it are running slow. This is the essential tool for getting the best bang for your buck in speeding up code.</p>
<p>R’s code profiler samples the “call stack” at regular intervals. The call stack is the list of the current function running, the function that called it, and all the functions that <em>those</em>. By examining these samples, you can find which functions are taking up the largest amount of time, either because they are slow or are called many times.</p>
<p>You activate the profiler with <code>Rprof(&quot;filename&quot;)</code> which writes each sample of the call stack to “filename”. So do this:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Rprof</span>(<span class="st">&quot;file.out&quot;</span>)
<span class="kw">Some_slow_code</span>()
<span class="kw">Rprof</span>(<span class="ot">NULL</span>)
<span class="kw">summaryRprof</span>(<span class="st">&quot;file.out&quot;</span>)</code></pre>
<p><code>Rprof(NULL)</code> stops sampling and <code>summaryRprof(&quot;file.out&quot;)</code> gives you a summary of the results. Here’s an example of profiling a random walk function (from a <a href="http://www.stat.auckland.ac.nz//~ihaka/downloads/Taupo-handouts.pdf">talk by Duncan Temple Lang</a>):</p>
<pre class="sourceCode r"><code class="sourceCode r">rw2s1 &lt;-<span class="st"> </span>function(n) {
    xpos =<span class="st"> </span>ypos =<span class="st"> </span><span class="kw">numeric</span>(n)
    xdir =<span class="st"> </span><span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">FALSE</span>)
    pm1 =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, -<span class="dv">1</span>)
    for (i in <span class="dv">2</span>:n) if (<span class="kw">sample</span>(xdir, <span class="dv">1</span>)) {
        xpos[i] =<span class="st"> </span>xpos[i -<span class="st"> </span><span class="dv">1</span>] +<span class="st"> </span><span class="kw">sample</span>(pm1, <span class="dv">1</span>)
        ypos[i] =<span class="st"> </span>ypos[i -<span class="st"> </span><span class="dv">1</span>]
    } else {
        xpos[i] =<span class="st"> </span>xpos[i -<span class="st"> </span><span class="dv">1</span>]
        ypos[i] =<span class="st"> </span>ypos[i -<span class="st"> </span><span class="dv">1</span>] +<span class="st"> </span><span class="kw">sample</span>(pm1, <span class="dv">1</span>)
    }
    <span class="kw">list</span>(<span class="dt">x =</span> xpos, <span class="dt">y =</span> ypos)
}

<span class="kw">Rprof</span>(<span class="st">&quot;out.out&quot;</span>)
for (i in <span class="dv">1</span>:<span class="dv">1000</span>) pos =<span class="st"> </span><span class="kw">rw2s1</span>(<span class="dv">1000</span>)
<span class="kw">Rprof</span>(<span class="ot">NULL</span>)
<span class="kw">summaryRprof</span>(<span class="st">&quot;out.out&quot;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">## $by.self
##              self.time self.pct total.time total.pct
## &quot;sample.int&quot;      7.62    47.04       7.62     47.04
## &quot;rw2s1&quot;           5.28    32.59      16.20    100.00
## &quot;sample&quot;          2.90    17.90      10.52     64.94
## &quot;-&quot;               0.30     1.85       0.30      1.85
## &quot;+&quot;               0.04     0.25       0.04      0.25
## &quot;list&quot;            0.04     0.25       0.04      0.25
## &quot;numeric&quot;         0.02     0.12       0.02      0.12
## 
## $by.total
##              total.time total.pct self.time self.pct
## &quot;rw2s1&quot;           16.20    100.00      5.28    32.59
## &quot;sample&quot;          10.52     64.94      2.90    17.90
## &quot;sample.int&quot;       7.62     47.04      7.62    47.04
## &quot;-&quot;                0.30      1.85      0.30     1.85
## &quot;+&quot;                0.04      0.25      0.04     0.25
## &quot;list&quot;             0.04      0.25      0.04     0.25
## &quot;numeric&quot;          0.02      0.12      0.02     0.12
## 
## $sample.interval
## [1] 0.02
## 
## $sampling.time
## [1] 16.2</code></pre>
<p>The two tables list the functions called. The <code>$by.self</code> component lists the time spent by <em>functions alone</em>, while the <code>$by.total</code> table lists the time spent by <em>functions and all the functions they call</em>. So you see that <code>rw2s1</code>, being the <em>parent function</em>, takes the most time in <code>$by.total</code>, but <code>sample.int</code> is the bottom-level function that is taking the most time.</p>
<p>I don’t find this <code>summaryRprof()</code> output very intuitive. There are some moderately better tools out there in the packages <code>profr</code> and <code>proftool</code>, but I don’t like them either. Instead I’ve written a custom function that you can get <a href="https://github.com/noamross/noamtools/blob/master/R/proftable.R">here</a> called <code>proftable</code>. Here it parses the same output as above:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">proftable</span>(<span class="st">&quot;out.out&quot;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">##  PctTime Stack                      
##  47.037  rw2s1 &gt; sample &gt; sample.int
##  32.593  rw2s1                      
##  17.901  rw2s1 &gt; sample             
##   1.852  rw2s1 &gt; -                  
##   0.247  rw2s1 &gt; +                  
##   0.247  rw2s1 &gt; list               
##   0.123  rw2s1 &gt; numeric            
## 
## Total Time: 16.2 seconds</code></pre>
<p>Here you can see that &gt;50% of time is being taken up by <code>sample.int</code>, which is itself usually called by <code>sample</code>.</p>
<h4 id="misc-profiling-things">Misc profiling things</h4>
<ul>
<li><p>The latest version of R (3.0.0) allows code profiling by <em>line number</em> using <code>Rprof(file, line.profiling=TRUE)</code> and <code>summaryRprof(file, lines=&quot;show&quot;)</code>. I don’t yet have a good example of it and haven’t incorporated this function into <code>proftable()</code> yet. There’s an example of use <a href="http://stackoverflow.com/a/15821706/1757441">at Stack Overflow</a></p></li>
<li><p>Note that, depending on the R interface you are using, it may wrap your code in some other functions, which will appear as the topmost functions in the stack. For instance, if use the “Source” button in Rtudio, all your stacks will start with something like:</p>
<pre class="sourceCode r"><code class="sourceCode r">source &gt;<span class="st"> </span>withVisible &gt;<span class="st"> </span>eval &gt;<span class="st"> </span>eval &gt;</code></pre>
<p><strong>[Update 5/8/2003: The <a href="https://github.com/noamross/noamtools/blob/master/R/proftable.R">latest verion</a> of <code>proftable</code> can deal with line numbers. It also deals with wrapper stacks like above.]</strong></p></li>
<li><p><code>trace()</code> can also be useful to track down where a particular slow function is being called. Try using <code>trace(function, tracer=cat(as.character(sys.calls()))</code>, for instance, to print the stack whenever <code>function</code> is called.</p></li>
<li><p>R also has the ability to do <em>memory profiling</em> - tracking how your code uses memory. These include <code>Rprofmem()</code>, <code>tracemem()</code>, and <code>Rprof(memory.profiling=TRUE)</code>, but the documentation for these isn’t great and I haven’t found good resources on this topic. Let me know if you can point me to some resources.</p></li>
<li><p>Jeromy Anglim has a blog post of an <code>Rprof()</code> <a href="http://jeromyanglim.blogspot.com/2010/02/case-study-in-optimising-code-in-r.html">case study</a> that is worth reading</p></li>
</ul>
<h2 id="find-better-packages">Find better packages</h2>
<p>Before you go about changing your own code, take a look and see if you can use better code someone else has written. There are thousands of packages on CRAN, but many of them are redundant and implement the same thing. There’s tremendous variation in package quality and speed, so you can often speed things up by finding a faster package.</p>
<p>For instance, the <code>xts</code> and <code>zoo</code> packages both handle time series data, but much of <code>xts</code> is written in C and Fortran, and it is considerably faster. Here are some performance benchmarks (though they are a bit out of date):</p>
<div class="figure">
<img src="http://dl.dropbox.com/u/3356641/blogstuff/xtsperformance.png" alt="Comparison of functions on xts time series objects against time series from other packages. From this presentation" /><p class="caption">Comparison of functions on xts time series objects against time series from other packages. From <a href="http://www.quantmod.com/Columbia2008/ColumbiaDec4.pdf">this presentation</a></p>
</div>
<p>Other packages are specifically designed to speed up certain operations. Some creative googling (e.g., <em>r package CRAN fast “something”</em>) will help you find them.</p>
<p>For instance. Using base functions like <code>colMeans()</code> is faster than using <code>apply</code> functions to apply <code>mean</code>. The <code>matrixStats</code> package extends these functions to include others like <code>rowMaxs()</code>, <code>colRanks()</code>, etc.</p>
<p><code>data.table</code> is a package designed for speeding up data frame operations when working very large datasets. <code>data.table</code>’s biggest advantage is in tasks like sub-setting and indexing. Here I compare the two in looking up the value of a row:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(data.table)
myDF &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">matrix</span>(<span class="kw">rnorm</span>(<span class="fl">1e+05</span>), <span class="dv">10000</span>, <span class="dv">10</span>))
myDF$key &lt;-<span class="st"> </span><span class="kw">as.character</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(myDF))
myDT &lt;-<span class="st"> </span><span class="kw">data.table</span>(myDF)
<span class="kw">setkey</span>(myDT, key)
<span class="kw">microbenchmark</span>(myDF[myDF$key ==<span class="st"> </span><span class="dv">2</span>, ], myDT[<span class="st">&quot;2&quot;</span>, ])</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">## Unit: microseconds
##                   expr    min     lq median   uq  max neval
##  myDF[myDF$key == 2, ] 2658.8 2885.3   3187 3755 6434   100
##            myDT[&quot;2&quot;, ]  724.3  899.7   1112 1393 4287   100</code></pre>
<p>Here <code>data.table</code> is 3X times faster. It gets faster with larger data sets.</p>
<h2 id="improving-your-code">Improving your code</h2>
<p>Once you know what parts of your code are slowing you down, and you have a method to test speed, you need tools and options for writing faster functions. Here are a few.</p>
<h3 id="vectorization">Vectorization</h3>
<p>This is the first thing most guides to coding discuss, so I won’t go into in much. Basically, R is good at matrix/vector algebra, so if you can express something as</p>
<p><span class="math">\[\begin{bmatrix} x \\ y \\ z \end{bmatrix} + \begin{bmatrix} a \\ b \\ c \end{bmatrix} \]</span></p>
<p>It will go faster than</p>
<p><span class="math">\[\begin{aligned}
x + a \\
y + b \\
z + c \\
\end{aligned}\]</span></p>
<p>Or, in R</p>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>) +<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)</code></pre>
<p>Instead of</p>
<pre class="sourceCode r"><code class="sourceCode r">for(i in <span class="dv">1</span>:<span class="dv">3</span>) x[i] &lt;-<span class="st"> </span>i+i</code></pre>
<ul>
<li><p>Most base R functions are designed to handle vectors as well as scalars.</p></li>
<li><p>However, using an <code>apply</code> function is not really vectorization. <code>apply</code> functions are actually wrappers for <code>for</code> loops</p></li>
<li><p>For more on vectorization, see Chapters 3 and 4 of <a href="http://www.burns-stat.com/pages/Tutor/R_inferno.pdf">The R Inferno</a></p></li>
</ul>
<h3 id="pre-allocating-memory">Pre-allocating memory</h3>
<p>Again, a common topic I won’t dwell on too much. Essentially, R is bad at continually re-sizing objects, because it makes an extra copy of these objects each time. So if you have a loop that creates a vector or list, don’t append to the vector or list with each pass of the loop. Instead, make an <em>empty</em> object of the correct size first, then fill in its elements.</p>
<p>More <a href="http://musicallyut.blogspot.com/2012/07/pre-allocate-your-vectors.html">here</a></p>
<p>The <code>apply</code> family of functions helps you avoid these problems by doing pre-allocation automatically. Plus, as I wrote above, if you use <code>apply</code> variants, it’s easy to parallelize your code.</p>
<h3 id="using-simpler-data-structures">Using simpler data structures</h3>
<p>R has some very handy objects, lists and dataframes, that are flexible and can store multiple types of data at once. However, this flexibility comes at a cost. Simpler data structures that only store <em>one</em> type of data can be manipulated much faster. If you can represent data in a matrix instead of a data frame (e.g., if you can reduce it to all numbers or characters), you can speed things up considerably.</p>
<p>For instance, compare these operations for getting the standard deviation of 100,000 rows of 10 variables in both a matrix and a data frame:</p>
<pre class="sourceCode r"><code class="sourceCode r">myMatrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(<span class="fl">1e+05</span>), <span class="dv">10000</span>, <span class="dv">100</span>)
myDF &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(myMatrix)
<span class="kw">microbenchmark</span>(<span class="kw">apply</span>(myMatrix, <span class="dv">2</span>, sd), <span class="kw">apply</span>(myDF, <span class="dv">2</span>, sd))</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">## Unit: milliseconds
##                    expr   min    lq median    uq    max neval
##  apply(myMatrix, 2, sd) 29.70 31.60  33.04 34.65  94.21   100
##      apply(myDF, 2, sd) 39.69 70.14  96.61 98.81 250.12   100</code></pre>
<h3 id="the-small-stuff">The small stuff</h3>
<p>Little things can add up, but the little things are most likely not your main problem. Here are a few odds and ends I’ve discovered. They’ll shave a few percent off your run time, but thinking about them too much will add hours to your coding time.</p>
<h4 id="extra-parentheses">Extra parentheses</h4>
<p>Sometimes when I write complex mathematical expressions I include extra parentheses to help make the code more readable. This has a small performance cost, as you can see here:</p>
<pre class="sourceCode r"><code class="sourceCode r">a &lt;-<span class="st"> </span>function(x) x =<span class="st"> </span><span class="dv">1</span>/{
    <span class="dv">1</span> +<span class="st"> </span>x
}
f &lt;-<span class="st"> </span>function(x) x =<span class="st"> </span><span class="dv">1</span>/(<span class="dv">1</span> +<span class="st"> </span>x)
g &lt;-<span class="st"> </span>function(x) x =<span class="st"> </span>(<span class="dv">1</span>/(<span class="dv">1</span> +<span class="st"> </span>x))
h &lt;-<span class="st"> </span>function(x) x =<span class="st"> </span>((<span class="dv">1</span>/(<span class="dv">1</span> +<span class="st"> </span>x)))
k &lt;-<span class="st"> </span>function(x) x =<span class="st"> </span>(((<span class="dv">1</span>/(<span class="dv">1</span> +<span class="st"> </span>x))))
x &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:<span class="dv">100</span>, <span class="dv">100</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
comp &lt;-<span class="st"> </span><span class="kw">microbenchmark</span>(<span class="kw">a</span>(x), <span class="kw">f</span>(x), <span class="kw">g</span>(x), <span class="kw">h</span>(x), <span class="kw">k</span>(x), <span class="dt">times =</span> <span class="fl">1e+05</span>)
comp</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">## Unit: microseconds
##  expr   min    lq median    uq   max neval
##  a(x) 1.991 2.197  2.313 2.971 11068 1e+05
##  f(x) 1.960 2.174  2.292 2.990 10435 1e+05
##  g(x) 2.090 2.302  2.427 3.112 10755 1e+05
##  h(x) 2.188 2.406  2.536 3.178  9660 1e+05
##  k(x) 2.259 2.504  2.644 3.367 11228 1e+05</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">autoplot</span>(comp)</code></pre>
<div class="figure">
<img src="http://dl.dropbox.com/u/3356641/blogstuff/unnamed-chunk-6.png" />
</div>
<p>The difference is modest, but each layer of parentheses adds a bit to performance time. Note that, amazingly, r speeds up when you use curly braces (<code>{</code> and <code>}</code>) instead of parentheses! Why? <a href="http://radfordneal.wordpress.com/2010/08/19/speeding-up-parentheses-and-lots-more-in-r/">Radford Neal explains</a>:</p>
<blockquote>
<p>The difference between parentheses and curly brackets comes about because R treats curly brackets as a “special” operator, whose arguments are not automatically evaluated, but it treats parentheses as a “built in” operator, whose arguments (just one for parentheses) are evaluated automatically, with the results of this evaluation stored in a LISP-style list. Creating this list requires allocation of memory and other operations which seem to be slow enough to cause the difference, since the curly bracket operator just evaluates the expressions inside and returns the last of them, without creating such a list.</p>
</blockquote>
<h4 id="standard-and-internal-functions">Standard and internal functions</h4>
<p>A few standard functions in R are pretty slow, often because they perform error checking and methods dispatch before actually doing arithmetic. <code>mean</code> is among the most notorious of these. <code>mean(x)</code>does a lot more than just <code>sum(x)/length(x)</code>. It checks the form of the inputs, assigns the appropriate method, then dispatches <code>.Internal(mean(x))</code>. The latter is much faster, as it is written in C:</p>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:<span class="dv">100</span>, <span class="dv">100</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
comp &lt;-<span class="st"> </span><span class="kw">microbenchmark</span>(<span class="kw">mean</span>(x), <span class="kw">sum</span>(x)/<span class="kw">length</span>(x), <span class="kw">.Internal</span>(<span class="kw">mean</span>(x)), <span class="dt">times =</span> <span class="fl">1e+05</span>)
comp</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">## Unit: nanoseconds
##                expr  min   lq median   uq      max neval
##             mean(x) 5671 6136   6386 6792 61466725 1e+05
##    sum(x)/length(x)  720  878   1064 1211  1511792 1e+05
##  .Internal(mean(x))  513  556    614  677  1082112 1e+05</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">autoplot</span>(comp)</code></pre>
<div class="figure">
<img src="http://dl.dropbox.com/u/3356641/blogstuff/unnamed-chunk-7.png" />
</div>
<p>You can sometimes get away with using the internal functions like <code>.Internal(mean(x))</code>. However, this is considered poor practice because (a) internals are subject to change and break your code with updates to R, and (b) this is disallowed in packages submitted to CRAN, so it makes code more difficult to share. That said, the internal version can be 9X faster. Your call.</p>
<p><strong><em>[Update 4/26/2013: On the <a href="https://twitter.com/kevin_ushey/status/327205714328158208">suggestion of Kevin Ushey</a>, I’m adding the following section]</em></strong></p>
<h1 id="other-languages-more-reward-for-more-effort">Other Languages: More reward for more effort</h1>
<p>I’ve mentioned a few times that functions written in other languages, like C or C++, are much faster than other R functions. Obviously, learning another language is an undertaking, but thanks to some recent developments, writing R functions in C has become much easier. The <code>Rcpp</code> package lets you write such C++ functions without learning much about compiling or other peripheral issues, and Hadley Wyckham has written an <a href="https://github.com/hadley/devtools/wiki/Rcpp">excellent beginners’s guide to <code>Rcpp</code></a> that teaches you just enough C++ to get started. From the guide:</p>
<blockquote>
<p>Typical bottlenecks that C++ can help with are:</p>
<ul>
<li><p>Loops that can’t easily be vectorised because each iteration depends on the previous. C++ modifies objects in place, so there is little overhead when modifying a data structure many times.</p></li>
<li><p>Recursive functions, or problems which involve calling functions millions of times. The overhead of calling a function in C++ is much lower than the overhead of calling a function in R. To give you some idea of the magnitude, on my computer when writing this book the overhead in C++ was ~5ns compared to ~200ns for R.</p></li>
<li><p>Problems that require advanced data structures and algorithms that R doesn’t provide. Through the standard &gt;template library (STL), C++ has efficient implementations of many important data structures, from ordered maps &gt;to double ended queues.</p></li>
</ul>
</blockquote>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>I used to also have a reference here that <code>x*x</code> is faster than <code>x^2</code> in R, but as <a href="http://simplystatistics.org/2013/04/28/sunday-datastatistics-link-roundup-4282013/#comment-879142735">Thomas Lumley points out</a>, this hasn’t been true for a while, and some quick empirical testing confirmed that the two are pretty close.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>If you are a scientist, you should ALWAYS be prepared to share your code, and should probably publish it as a supplement to your papers.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>There are cheaper services than Amazon, but there aren’t as many resources on how to use them. If you really need to reduce costs, you can use <a href="http://aws.amazon.com/ec2/spot-instances/"><em>spot instances</em></a>, which allow you to set an allowable price, and run your program when something that cheap is available. Also, you could run many small Amazon virtual machines simultaneously on a free trial account, but if your goal is to do things <em>quickly</em>, it might be worth paying for a more powerful machine.<a href="#fnref3">↩</a></p></li>
</ol>
</div></p></div>
<ul class="tags">
  
    <li><strong>Tags: </strong></li>
    
    <li><a href="/tags.html#R-ref">R</a></li>
    
    <li><a href="/tags.html#D-RUG-ref">D-RUG</a></li>
      
</ul>



  <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'noamrossgh'; // required: replace example with your forum shortname
    var disqus_identifier = '/blog/2013/4/25/faster-talk.html';
    var disqus_url = 'http://www.noamross.net/blog/2013/4/25/faster-talk.html';
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>





<div class="noprint"><hr />
<p> <strong>Previous Post</strong>: <em><a href="/blog/2013/4/24/automating-preprints.html">Setting up Automated Reprint Requests in Gmail</a></em> </p>
<p> <strong>Next Post</strong>: <em><a href="/blog/2013/5/2/improved-r-profiling-summaries.html">Improved R Profiling Summaries</a></em> </p></div>



        </div>
    

      </div>
      
<script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1.6.1/jquery.min.js"></script>
<script type="text/javascript" src="/assets/themes/noamblog/footnote-links.js"></script>
<script type="text/javascript">$('div.contenttext').footnoteLinks();</script>
</body>
</html>
